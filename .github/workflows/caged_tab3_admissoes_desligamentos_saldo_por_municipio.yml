# This workflow will install Python dependencies, run tests and lint with a single version of Python
# For more information see: https://help.github.com/actions/language-and-framework-guides/using-python-with-github-actions

name: Scrap Caged Tabela 3

on:
  workflow_dispatch:

jobs:
  import_libs_and_do_scrap_tab3:

    runs-on: ubuntu-latest
    #env:
    #  AWS_DEFAULT_REGION: us-east-1
      
    #permissions:
    #  id-token: write
    #  contents: read

    steps:
    - uses: actions/checkout@v2
    - name: Set up Python 3.9
      uses: actions/setup-python@v2
      with:
        python-version: "3.9"
    - name: Install lib pandas
      run: |
        python -m pip install --upgrade pip
        pip install pandas
    - name: Install lib numpy
      run: pip install numpy
    - name: Install lib datetime
      run: pip install datetime
    - name: Install lib requests
      run: pip install requests
    - name: Install lib bs4
      run: pip install bs4
    - name: Install lib botocore
      run: pip install botocore    
    - name: Install lib boto3
      run: pip install boto3  
    - name: Install lib openpyxl
      run: pip install openpyxl
      
    - name: scrap_tabela_caged
      run: |
          pwd;ls;python scripts/caged_tab3.py

        
    - name: upload tabela csv
      run:  pwd;ls -l;mkdir transferir;cp df_caged_tab3.csv transferir; ls transferir
    - uses: actions/upload-artifact@v1
      with:
         name: df_caged_tab3.csv
         path: transferir
   #####################################################      
  download_file:
    name: get_cred_and_copy_table_to s3
    runs-on: ubuntu-latest
    env:
      AWS_DEFAULT_REGION: us-east-1
      
    permissions:
      id-token: write
      contents: read
    needs: import_libs_and_do_scrap_tab3
    steps:
     - uses: actions/download-artifact@v1
       with:
          name: df_caged_tab3.csv
          path: .
     - name: Install lib pandas
       run: pip install pandas
      
     - name: get aws credential
       uses: aws-actions/configure-aws-credentials@v1
       with:
          role-to-assume: arn:aws:iam::${{secrets.id}}:role/github-actions-role
          aws-region: ${{env.AWS_DEFAULT_REGION}}    
     - name: copy csv table to bucket
       run: |
          pwd;ls -l ;echo "Copy csv";aws s3 cp df_caged_tab3.csv s3://s3-caged;
          
     - name : copy parquet to bucket     
       run: |
          pwd;import pandas as pd;df = pd.read_csv("df_caged_tab3.csv"); ls -l;echo "Copy parquet";aws s3 cp df_caged_tab3.parquet s3://s3-caged;
        
